{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion done using UniProKB\n",
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = pd.read_csv('g1.tsv', sep='\\t')\n",
    "conv1 = conv1.rename(columns={\"yourlist:M201908296746803381A1F0E0DB47453E0216320D99E33CI\":\"Gene\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = conv1[['Gene', 'Sequence']]\n",
    "g1 = conv1['Gene'].to_list()\n",
    "p1 = conv1['Sequence'].to_list()\n",
    "conv_dict_1 = dict(zip(g1, p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(conv_dict_1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7865\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('1.txt', sep='\\t')\n",
    "gene_list_1 = df1['Gene1'].to_list()\n",
    "gene_list_2 = df1['Gene2'].to_list()\n",
    "assert len(gene_list_1) == len(gene_list_2)\n",
    "print(len(gene_list_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_keys(keys, d, ref_list):\n",
    "    for k in keys:\n",
    "        k_array = k.split(',')\n",
    "        if len(k_array) > 1:\n",
    "            for i in range(len(k_array)):\n",
    "                if k_array[i] in ref_list:\n",
    "                    d[k_array[i]] = d[k]\n",
    "            del d[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_keys(keys, conv_dict_1, gene_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MEFPLAQICPQGSHEAPIPTFSTFQITDMTRRSCQNLGYTAASPQAPEAASNTGNAERAEEVPGEGSLFLQAETRAWFQKTQAHWLLQHGAAPAWFHGFITRREAERLLEPKPQGCYLVRFSESAVTFVLTYRSRTCCRHFLLAQLRDGRHVVLGEDSAHARLQDLLLHYTAHPLSPYGETLTEPLARQTPEPAGLSLRTEESNFGSKSQDPNPQYSPIIKQGQAPVPMQKEGAGEKEPSQLLRPKPPIPAKPQLPPEVYTIPVPRHRPAPRPKPSNPIYNEPDEPIAFYAMGRGSPGEAPSNIYVEVEDEGLPATLGHPVLRKSWSRPVPGGQNTGGSQLHSENSVIGQGPPLPHQPPPAWRHTLPHNLSRQVLQDRGQAWLPLGPPQ'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_dict_1['SH2D2A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = pd.read_csv('g2.tsv', sep='\\t')\n",
    "conv2 = conv2.rename(columns={\"yourlist:M201908296746803381A1F0E0DB47453E0216320D99E36A3\":\"Gene\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = conv2[['Gene', 'Sequence']]\n",
    "g2 = conv2['Gene'].to_list()\n",
    "p2 = conv2['Sequence'].to_list()\n",
    "conv_dict_2 = dict(zip(g2, p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys2 = list(conv_dict_2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_keys(keys2, conv_dict_2, gene_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSLLNKPKSEMTPEELQKREEEEFNTGPLSVLTQSVKNNTQVLINCRNNKKLLGRVKAFDRHCNMVLENVKEMWTEVPKSGKGKKKSKPVNKDRYISKMFLRGDSVIVVLRNPLIAGK'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_dict_2['SNRPD2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dict_2['HIST1H3E'] = 'MQIFVKTLTGKTITLEVEPSDTIENVKAKIQDKEGIPPDQQRLIFAGKQLEDGRTLSDYNIQKESTLHLVLRLRGC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dict_1['HIST2H3A'] = 'KSTELLIRKLPFQRLVREIAQDFKTDLRFQSSAVMALQEASEAYLVGLFEDTNLCAIHAKRVTIMPKDIQLARRIRGERA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dict_2['XIST'] = 'GGCGCAUCGGCGCC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('protein_positive_a.txt', 'w') as f1, \\\n",
    "    open('protein_positive_b.txt', 'w') as f2:\n",
    "    for g1,g2 in zip(gene_list_1, gene_list_2):\n",
    "        f1.write('_' + conv_dict_1[g1] + '\\n')\n",
    "        f2.write('_' + conv_dict_2[g2] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = pd.read_csv('human_all.tsv', sep='\\t')\n",
    "neg = neg[['Sequence', 'Subcellular location [CC]']]\n",
    "neg = neg.rename(columns={\"Subcellular location [CC]\":\"Location\"})\n",
    "neg = neg[neg['Location'].isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish negative interaction set\n",
    "neg_size = len(gene_list_1)\n",
    "with open('protein_negative_a.txt', 'w') as f1, \\\n",
    "    open('protein_negative_b.txt', 'w') as f2:\n",
    "    for _ in range(neg_size):\n",
    "        sampled_data = neg.sample(n=2)\n",
    "        sample_loc = sampled_data['Location'].to_list()\n",
    "        #randomly sample from different subcellular locations\n",
    "        while sample_loc[0] == sample_loc[1]:\n",
    "            sampled_data = neg.sample(n=2)\n",
    "            sample_loc = sampled_data['Location'].to_list()\n",
    "        seq = sampled_data['Sequence'].to_list()\n",
    "        f1.write('_' + seq[0] + '\\n')\n",
    "        f2.write('_' + seq[1] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['protein_positive_a.txt', 'protein_negative_a.txt', 'protein_positive_b.txt', 'protein_negative_b.txt']\n",
    "with open('all_proteins.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                if line[0] == '_':\n",
    "                    outfile.write(line[1:])\n",
    "                else:\n",
    "                    outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a sentence piece model to segment proteins\n",
    "spm.SentencePieceTrainer.Train('--input=/Users/Kbutterstrap/Desktop/PPI_Code/all_proteins.txt --model_prefix=/Users/Kbutterstrap/Desktop/PPI_Code/seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '/Users/Kbutterstrap/Desktop/PPI_Code/seg.model'\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['protein_positive_a.txt', 'protein_negative_a.txt']\n",
    "with open('proteins_a.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['protein_positive_b.txt', 'protein_negative_b.txt']\n",
    "with open('proteins_b.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenized_a.txt', 'w') as f, \\\n",
    "    open('proteins_a.txt', 'r') as f_a:\n",
    "    start = 0\n",
    "    for lines in f_a:\n",
    "        #first line of the file\n",
    "        if start == 0:\n",
    "            current_protein = lines[1:]\n",
    "        #first line of another protein sequence\n",
    "        if (lines[0] == '_') & (start != 0):\n",
    "            token_list = sp.EncodeAsPieces(current_protein)\n",
    "            for t in token_list:\n",
    "                if token_list.index(t) == 0:\n",
    "                    f.write('\\n' + '_' + t + ' ')\n",
    "                else:\n",
    "                    f.write(t + ' ')\n",
    "            current_protein = lines[1:]\n",
    "        #within the range of one protein sequence\n",
    "        else:\n",
    "            current_protein += lines\n",
    "            start += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenized_b.txt', 'w') as f, \\\n",
    "    open('proteins_b.txt', 'r') as f_a:\n",
    "    start = 0\n",
    "    for lines in f_a:\n",
    "        #first line of the file\n",
    "        if start == 0:\n",
    "            current_protein = lines[1:]\n",
    "        #first line of another protein sequence\n",
    "        if (lines[0] == '_') & (start != 0):\n",
    "            token_list = sp.EncodeAsPieces(current_protein)\n",
    "            for t in token_list:\n",
    "                if token_list.index(t) == 0:\n",
    "                    f.write('\\n' + '_' + t + ' ')\n",
    "                else:\n",
    "                    f.write(t + ' ')\n",
    "            current_protein = lines[1:]\n",
    "        #within the range of one protein sequence\n",
    "        else:\n",
    "            current_protein += lines\n",
    "            start += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
